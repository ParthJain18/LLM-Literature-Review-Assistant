{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Inputs","metadata":{}},{"cell_type":"code","source":"# Write the search query for searching Semantic scholar\nsearch_query = '(LLM | LLMs | \"Large Language Models\") (\"thematic analysis\" | \"qualitative analysis\")'\n# Provide Gemini API keys within as strings the list. (For API key rotation, to avoid rate limits) eg. [\"api_key_1\", ...]\ngemini_api_keys = []\n# Provide research objectives (Used within the prompt for screening)\nresearch_objectives = \"To study the trends in automation in thematic analysis or qualitative analysis using LLMs\"\n# Provide the criteria by which the LLM should decide whether to accept the paper or not.\ndecision_criteria = \"ONLY accept the papers that discuss using LLMs for aiding or automating the process of thematic analysis or qualitative analysis. Be very selective.\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T11:28:53.254969Z","iopub.execute_input":"2025-05-08T11:28:53.255959Z","iopub.status.idle":"2025-05-08T11:28:53.261626Z","shell.execute_reply.started":"2025-05-08T11:28:53.255914Z","shell.execute_reply":"2025-05-08T11:28:53.260478Z"}},"outputs":[],"execution_count":130},{"cell_type":"markdown","source":"# Data collection","metadata":{}},{"cell_type":"code","source":"import requests","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T08:47:35.046682Z","iopub.execute_input":"2025-05-08T08:47:35.046946Z","iopub.status.idle":"2025-05-08T08:47:35.166903Z","shell.execute_reply.started":"2025-05-08T08:47:35.046925Z","shell.execute_reply":"2025-05-08T08:47:35.166214Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"bulk_search_url = \"https://api.semanticscholar.org/graph/v1/paper/search/bulk\"\nbulk_paper_detail_url = \"https://api.semanticscholar.org/graph/v1/paper/batch\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T09:23:34.718783Z","iopub.execute_input":"2025-05-08T09:23:34.719441Z","iopub.status.idle":"2025-05-08T09:23:34.723821Z","shell.execute_reply.started":"2025-05-08T09:23:34.719402Z","shell.execute_reply":"2025-05-08T09:23:34.722939Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"params = {\n    \"query\": search_query\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T09:07:49.198138Z","iopub.execute_input":"2025-05-08T09:07:49.198941Z","iopub.status.idle":"2025-05-08T09:07:49.202516Z","shell.execute_reply.started":"2025-05-08T09:07:49.198916Z","shell.execute_reply":"2025-05-08T09:07:49.201754Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"response = requests.get(bulk_search_url, params=params)\npapers_result = {}\nif response.status_code == 200:\n    papers_result = response.json()\n    print(\"Success!\")\nelse:\n    print(\"Error:\", response.status_code, response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T09:08:16.517384Z","iopub.execute_input":"2025-05-08T09:08:16.517660Z","iopub.status.idle":"2025-05-08T09:08:17.556078Z","shell.execute_reply.started":"2025-05-08T09:08:16.517639Z","shell.execute_reply":"2025-05-08T09:08:17.555469Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"papers = papers_result.get(\"data\", [])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T09:09:15.691355Z","iopub.execute_input":"2025-05-08T09:09:15.691649Z","iopub.status.idle":"2025-05-08T09:09:15.695729Z","shell.execute_reply.started":"2025-05-08T09:09:15.691630Z","shell.execute_reply":"2025-05-08T09:09:15.694819Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"paper_ids = [paper.get(\"paperId\", None) for paper in papers]\nparams = {\n    \"fields\": 'url,title,abstract,publicationDate,fieldsOfStudy,journal,authors,tldr,citationCount,referenceCount,externalIds'\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T09:28:12.512036Z","iopub.execute_input":"2025-05-08T09:28:12.512390Z","iopub.status.idle":"2025-05-08T09:28:12.516685Z","shell.execute_reply.started":"2025-05-08T09:28:12.512366Z","shell.execute_reply":"2025-05-08T09:28:12.515862Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"response = requests.post(bulk_paper_detail_url, json={\"ids\": paper_ids}, params=params)\ndetailed_result = {}\nif response.status_code == 200:\n    detailed_result = response.json()\n    print(\"Success!\")\nelse:\n    print(\"Error:\", response.status_code, response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T09:29:08.481702Z","iopub.execute_input":"2025-05-08T09:29:08.482309Z","iopub.status.idle":"2025-05-08T09:29:10.361117Z","shell.execute_reply.started":"2025-05-08T09:29:08.482286Z","shell.execute_reply":"2025-05-08T09:29:10.360344Z"}},"outputs":[{"name":"stdout","text":"Success!\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"detailed_result[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T09:30:27.453900Z","iopub.execute_input":"2025-05-08T09:30:27.454482Z","iopub.status.idle":"2025-05-08T09:30:27.460034Z","shell.execute_reply.started":"2025-05-08T09:30:27.454456Z","shell.execute_reply":"2025-05-08T09:30:27.459251Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"{'paperId': '005eff447a1d7f915ea4b48ca17f430c37745b90',\n 'externalIds': {'ArXiv': '2305.12050',\n  'DBLP': 'journals/pacmse/MuraliMABCGFNR24',\n  'DOI': '10.1145/3643774',\n  'CorpusId': 258832882},\n 'url': 'https://www.semanticscholar.org/paper/005eff447a1d7f915ea4b48ca17f430c37745b90',\n 'title': 'AI-Assisted Code Authoring at Scale: Fine-Tuning, Deploying, and Mixed Methods Evaluation',\n 'abstract': 'Generative LLMs have been shown to effectively power AI-based code authoring tools that can suggest entire statements or blocks of code during code authoring. In this paper we present CodeCompose, an AI-assisted code authoring tool developed and deployed at Meta internally. CodeCompose is based on the InCoder LLM that merges generative capabilities with bi-directionality. We have scaled up CodeCompose to serve tens of thousands of developers at Meta, across 9 programming languages and several coding surfaces. We present our experience in making design decisions about the model and system architecture for CodeCompose that addresses these challenges. \\n \\n \\n \\n \\n \\n \\n \\nTo release a LLM model at this scale, we needed to first ensure that it is sufficiently accurate. In a random sample of 20K source code files, depending on the language, we are able to reproduce hidden lines between 40% and 58% of the time, an improvement of 1.4× and 4.1× over a model trained only on public data. \\n \\n \\n \\n \\n \\n \\n \\nWe gradually rolled CodeCompose out to developers. At the time of this writing, 16K developers have used it with 8% of their code coming directly from CodeCompose. \\n \\n \\n \\n \\n \\n \\n \\nTo triangulate our numerical findings, we conduct a thematic analysis on the feedback from 70 developers. We find that 91.5% of the feedback is positive, with the most common themes being discovering APIs, dealing with boilerplate code, and accelerating coding. Meta continues to integrate this feedback into CodeCompose.',\n 'referenceCount': 36,\n 'citationCount': 14,\n 'openAccessPdf': {'url': 'http://arxiv.org/pdf/2305.12050',\n  'status': 'GREEN',\n  'license': None,\n  'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2305.12050, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'},\n 'fieldsOfStudy': ['Computer Science'],\n 'tldr': {'model': 'tldr@v2.0.0',\n  'text': 'This paper presents CodeCompose, an AI-assisted code authoring tool developed and deployed at Meta internally, based on the InCoder LLM that merges generative capabilities with bi-directionality, and their experience in making design decisions about the model and system architecture that addresses these challenges.'},\n 'publicationDate': '2023-05-20',\n 'journal': {'name': 'Proc. ACM Softw. Eng.',\n  'pages': '1066-1085',\n  'volume': '1'},\n 'authors': [{'authorId': '32269195', 'name': 'V. Murali'},\n  {'authorId': '22192720', 'name': 'C. Maddila'},\n  {'authorId': '144959500', 'name': 'Imad Ahmad'},\n  {'authorId': '143764314', 'name': 'Michael Bolin'},\n  {'authorId': '2053698074', 'name': 'Daniel Cheng'},\n  {'authorId': '35543511', 'name': 'Negar Ghorbani'},\n  {'authorId': '2218099053', 'name': 'Renuka Fernandez'},\n  {'authorId': '1693689', 'name': 'Nachiappan Nagappan'},\n  {'authorId': '2265391422', 'name': 'Peter C. Rigby'}]}"},"metadata":{}}],"execution_count":52},{"cell_type":"markdown","source":"# AI screening","metadata":{}},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\nimport os\nimport time\nimport json\nimport random\nimport csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:44:55.665459Z","iopub.execute_input":"2025-05-08T10:44:55.665755Z","iopub.status.idle":"2025-05-08T10:44:55.670346Z","shell.execute_reply.started":"2025-05-08T10:44:55.665734Z","shell.execute_reply":"2025-05-08T10:44:55.669401Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"def chunked(iterable, size):\n    for i in range(0, len(iterable), size):\n        yield iterable[i:i + size]\n\ndef build_prompt(papers):\n    prompt = (\n        f\"\"\"You are a research assistant helping screen academic papers for a specific research goal.\\n\n        Here are 5 papers. For each paper, decide whether it aligns with the research objectives. \n        Research objectives are: {research_objectives}\n        You should return your decision as true if it meets the following criteria: {decision_criteria}\n        Give a general overview ('thoughts'), a binary decision, whether to include the paper to study or not ('decision' = true/false), and an optional note.\\n\\n\n        \"\"\"\n    )\n    for idx, paper in enumerate(papers, start=1):\n        prompt += (\n            f\"Paper {idx}:\\n\"\n            f\"Title: {paper.get('title', 'N/A')}\\n\"\n            f\"Abstract: {paper.get('abstract', 'N/A')}\\n\\n\"\n            f\"tldr: {paper.get('tldr', {}).get('text', 'N/A')}\\n\\n\"\n        )\n    prompt += (\n        \"Respond with a JSON list of 5 objects, each with keys: 'thoughts', 'decision', and 'note', \"\n        \"in the same order as the papers.\"\n    )\n    return prompt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:44:58.129963Z","iopub.execute_input":"2025-05-08T10:44:58.130255Z","iopub.status.idle":"2025-05-08T10:44:58.135751Z","shell.execute_reply.started":"2025-05-08T10:44:58.130235Z","shell.execute_reply":"2025-05-08T10:44:58.134925Z"}},"outputs":[],"execution_count":95},{"cell_type":"code","source":"CSV_FILE = \"/kaggle/working/screened_papers.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T11:06:07.715946Z","iopub.execute_input":"2025-05-08T11:06:07.716527Z","iopub.status.idle":"2025-05-08T11:06:07.720380Z","shell.execute_reply.started":"2025-05-08T11:06:07.716502Z","shell.execute_reply":"2025-05-08T11:06:07.719527Z"}},"outputs":[],"execution_count":110},{"cell_type":"code","source":"processed_ids = set()\nif os.path.exists(CSV_FILE):\n    with open(CSV_FILE, newline='', encoding='utf-8') as f:\n        reader = csv.DictReader(f)\n        processed_ids = {row[\"paperId\"] for row in reader}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:47:38.560879Z","iopub.execute_input":"2025-05-08T10:47:38.561178Z","iopub.status.idle":"2025-05-08T10:47:38.566709Z","shell.execute_reply.started":"2025-05-08T10:47:38.561157Z","shell.execute_reply":"2025-05-08T10:47:38.566025Z"}},"outputs":[],"execution_count":102},{"cell_type":"code","source":"MAX_RETRIES = 5\nINITIAL_BACKOFF = 2\n\nwith open(CSV_FILE, \"a\", newline='', encoding='utf-8') as csvfile:\n    writer = csv.DictWriter(csvfile, fieldnames=[\"paperId\", \"thoughts\", \"decision\", \"note\"])\n    if os.stat(CSV_FILE).st_size == 0:\n        writer.writeheader()\n\n    unprocessed = [paper for paper in detailed_result if paper['paperId'] not in processed_ids]\n\n    for i, batch in enumerate(chunked(unprocessed, 3)):\n        retries = 0\n        while retries < MAX_RETRIES:\n            try:\n                key_index = i % len(gemini_api_keys)\n                genai_client = genai.Client(api_key=gemini_api_keys[key_index])\n                model = \"gemini-2.0-flash\"\n                prompt_text = build_prompt(batch)\n                contents = [\n                    types.Content(\n                        role=\"user\",\n                        parts=[\n                            types.Part(text=prompt_text),\n                        ],\n                    ),\n                ]\n\n                generate_content_config = types.GenerateContentConfig(\n                        response_mime_type=\"application/json\",\n                        response_schema=genai.types.Schema(\n                            type = genai.types.Type.ARRAY,\n                            items = genai.types.Schema(\n                                type = genai.types.Type.OBJECT,\n                                required = [\"thoughts\", \"decision\"],\n                                properties = {\n                                    \"thoughts\": genai.types.Schema(\n                                        type = genai.types.Type.STRING,\n                                    ),\n                                    \"decision\": genai.types.Schema(\n                                        type = genai.types.Type.BOOLEAN,\n                                    ),\n                                    \"note\": genai.types.Schema(\n                                        type = genai.types.Type.STRING,\n                                    ),\n                                },\n                            ),\n                        ),\n                    )\n\n\n                result = genai_client.models.generate_content(\n                    model=model,\n                    contents=contents,\n                    config=generate_content_config\n                )\n\n                parsed_result = result.text\n                response_json = json.loads(parsed_result) if isinstance(parsed_result, str) else parsed_result\n                \n                for paper, response in zip(batch, response_json):\n                    writer.writerow({\n                        \"paperId\": paper['paperId'],\n                        \"thoughts\": response.get(\"thoughts\", \"\"),\n                        \"decision\": response.get(\"decision\", \"\"),\n                        \"note\": response.get(\"note\", \"\"),\n                    })\n                    csvfile.flush()\n\n                print(f\"Batch {i + 1} processed and saved.\")\n                break  # exit retry loop\n\n            except Exception as e:\n                print(f\"Error in batch {i + 1}, retrying ({retries + 1}/{MAX_RETRIES})...\")\n                print(f\"Exception: {e}\")\n                time.sleep(INITIAL_BACKOFF * (2 ** retries) + random.uniform(0, 1))\n                retries += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:48:01.005905Z","iopub.execute_input":"2025-05-08T10:48:01.006209Z","iopub.status.idle":"2025-05-08T10:51:37.934128Z","shell.execute_reply.started":"2025-05-08T10:48:01.006175Z","shell.execute_reply":"2025-05-08T10:51:37.933452Z"}},"outputs":[{"name":"stdout","text":"Batch 1 processed and saved.\nBatch 2 processed and saved.\nBatch 3 processed and saved.\nBatch 4 processed and saved.\nBatch 5 processed and saved.\nBatch 6 processed and saved.\nBatch 7 processed and saved.\nBatch 8 processed and saved.\nBatch 9 processed and saved.\nBatch 10 processed and saved.\nBatch 11 processed and saved.\nBatch 12 processed and saved.\nBatch 13 processed and saved.\nBatch 14 processed and saved.\nBatch 15 processed and saved.\nBatch 16 processed and saved.\nBatch 17 processed and saved.\nBatch 18 processed and saved.\nBatch 19 processed and saved.\nBatch 20 processed and saved.\nBatch 21 processed and saved.\nBatch 22 processed and saved.\nBatch 23 processed and saved.\nBatch 24 processed and saved.\nBatch 25 processed and saved.\nBatch 26 processed and saved.\nBatch 27 processed and saved.\nBatch 28 processed and saved.\nBatch 29 processed and saved.\nBatch 30 processed and saved.\nBatch 31 processed and saved.\nBatch 32 processed and saved.\nBatch 33 processed and saved.\nBatch 34 processed and saved.\nBatch 35 processed and saved.\nBatch 36 processed and saved.\nBatch 37 processed and saved.\nBatch 38 processed and saved.\nBatch 39 processed and saved.\nBatch 40 processed and saved.\nBatch 41 processed and saved.\nBatch 42 processed and saved.\nBatch 43 processed and saved.\nBatch 44 processed and saved.\nBatch 45 processed and saved.\nBatch 46 processed and saved.\nBatch 47 processed and saved.\nBatch 48 processed and saved.\nBatch 49 processed and saved.\nBatch 50 processed and saved.\nBatch 51 processed and saved.\nBatch 52 processed and saved.\nBatch 53 processed and saved.\nBatch 54 processed and saved.\nBatch 55 processed and saved.\nBatch 56 processed and saved.\nBatch 57 processed and saved.\nBatch 58 processed and saved.\nBatch 59 processed and saved.\nBatch 60 processed and saved.\nBatch 61 processed and saved.\nBatch 62 processed and saved.\nBatch 63 processed and saved.\nBatch 64 processed and saved.\nBatch 65 processed and saved.\nBatch 66 processed and saved.\nBatch 67 processed and saved.\nBatch 68 processed and saved.\nBatch 69 processed and saved.\nBatch 70 processed and saved.\nBatch 71 processed and saved.\nBatch 72 processed and saved.\nBatch 73 processed and saved.\nBatch 74 processed and saved.\nBatch 75 processed and saved.\nBatch 76 processed and saved.\nBatch 77 processed and saved.\nBatch 78 processed and saved.\nBatch 79 processed and saved.\nBatch 80 processed and saved.\n","output_type":"stream"}],"execution_count":103},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T10:29:40.390778Z","iopub.execute_input":"2025-05-08T10:29:40.391039Z","iopub.status.idle":"2025-05-08T10:29:40.767169Z","shell.execute_reply.started":"2025-05-08T10:29:40.391023Z","shell.execute_reply":"2025-05-08T10:29:40.766585Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"df1 = pd.read_csv(CSV_FILE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T11:06:12.994757Z","iopub.execute_input":"2025-05-08T11:06:12.995013Z","iopub.status.idle":"2025-05-08T11:06:13.017226Z","shell.execute_reply.started":"2025-05-08T11:06:12.994991Z","shell.execute_reply":"2025-05-08T11:06:13.016367Z"}},"outputs":[],"execution_count":111},{"cell_type":"code","source":"df1.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T11:06:24.469974Z","iopub.execute_input":"2025-05-08T11:06:24.470280Z","iopub.status.idle":"2025-05-08T11:06:24.479553Z","shell.execute_reply.started":"2025-05-08T11:06:24.470257Z","shell.execute_reply":"2025-05-08T11:06:24.478861Z"}},"outputs":[{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"                                    paperId  \\\n0  005eff447a1d7f915ea4b48ca17f430c37745b90   \n1  023b852cafd6bcc8dcb0f60e2513a597c0b3c793   \n2  02bcbd9c4e3d3dc2ccad4c61c27e21a50c765f62   \n3  02ce9267dbfa1df73b0a1b1e66f5ce6697d5e3b8   \n4  0364dc93966e4e81453aa3886ff5813327af01c4   \n\n                                               title  \\\n0  AI-Assisted Code Authoring at Scale: Fine-Tuni...   \n1  “Here the GPT made a choice, and every choice ...   \n2  LLMCode: Evaluating and Enhancing Researcher-A...   \n3  Small Language Models can Outperform Humans in...   \n4  The use of large language models for qualitati...   \n\n                                            abstract  \\\n0  Generative LLMs have been shown to effectively...   \n1                                                NaN   \n2  The use of large language models (LLMs) in qua...   \n3  In this paper, we evaluate the creative fictio...   \n4  Machine-assisted approaches for free-text anal...   \n\n                                            thoughts  decision  \\\n0  This paper uses thematic analysis to understan...      True   \n1  This paper discusses students' critical engage...     False   \n2  The paper introduces LLMCode, a tool to assess...      True   \n3  This paper compares creative writing abilities...     False   \n4  This paper presents DECOTA, a novel machine le...      True   \n\n                                                note  \n0  Thematic analysis is used as an evaluation met...  \n1                Thematic analysis is not the focus.  \n2  Focuses on AI assistance in qualitative analysis.  \n3                     No thematic analysis involved.  \n4              Directly automates thematic analysis.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paperId</th>\n      <th>title</th>\n      <th>abstract</th>\n      <th>thoughts</th>\n      <th>decision</th>\n      <th>note</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>005eff447a1d7f915ea4b48ca17f430c37745b90</td>\n      <td>AI-Assisted Code Authoring at Scale: Fine-Tuni...</td>\n      <td>Generative LLMs have been shown to effectively...</td>\n      <td>This paper uses thematic analysis to understan...</td>\n      <td>True</td>\n      <td>Thematic analysis is used as an evaluation met...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>023b852cafd6bcc8dcb0f60e2513a597c0b3c793</td>\n      <td>“Here the GPT made a choice, and every choice ...</td>\n      <td>NaN</td>\n      <td>This paper discusses students' critical engage...</td>\n      <td>False</td>\n      <td>Thematic analysis is not the focus.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>02bcbd9c4e3d3dc2ccad4c61c27e21a50c765f62</td>\n      <td>LLMCode: Evaluating and Enhancing Researcher-A...</td>\n      <td>The use of large language models (LLMs) in qua...</td>\n      <td>The paper introduces LLMCode, a tool to assess...</td>\n      <td>True</td>\n      <td>Focuses on AI assistance in qualitative analysis.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>02ce9267dbfa1df73b0a1b1e66f5ce6697d5e3b8</td>\n      <td>Small Language Models can Outperform Humans in...</td>\n      <td>In this paper, we evaluate the creative fictio...</td>\n      <td>This paper compares creative writing abilities...</td>\n      <td>False</td>\n      <td>No thematic analysis involved.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0364dc93966e4e81453aa3886ff5813327af01c4</td>\n      <td>The use of large language models for qualitati...</td>\n      <td>Machine-assisted approaches for free-text anal...</td>\n      <td>This paper presents DECOTA, a novel machine le...</td>\n      <td>True</td>\n      <td>Directly automates thematic analysis.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":113},{"cell_type":"markdown","source":"# Merging Data","metadata":{}},{"cell_type":"code","source":"import csv\nimport os\n\ndef flatten_paper_data(paper):\n    flat_data = {}\n\n    flat_data['paperId'] = paper.get('paperId', '')\n    flat_data['title'] = paper.get('title', '')\n    flat_data['abstract'] = paper.get('abstract', '')\n    flat_data['url'] = paper.get('url', '')\n    flat_data['referenceCount'] = paper.get('referenceCount', 0)\n    flat_data['citationCount'] = paper.get('citationCount', 0)\n    flat_data['publicationDate'] = paper.get('publicationDate', '')\n\n    if 'externalIds' in paper and isinstance(paper['externalIds'], dict):\n        flat_data['DOI'] = paper['externalIds'].get('DOI', '')\n    else:\n        flat_data['DOI'] = ''\n\n    if 'journal' in paper and isinstance(paper['journal'], dict):\n        flat_data['journal_name'] = paper['journal'].get('name', '')\n        flat_data['journal_pages'] = paper['journal'].get('pages', '')\n        flat_data['journal_volume'] = paper['journal'].get('volume', '')\n    else:\n        flat_data['journal_name'] = ''\n        flat_data['journal_pages'] = ''\n        flat_data['journal_volume'] = ''\n\n    if 'openAccessPdf' in paper and isinstance(paper['openAccessPdf'], dict):\n        flat_data['openAccessPdf_url'] = paper['openAccessPdf'].get('url', '')\n    else:\n        flat_data['openAccessPdf_url'] = ''\n\n    # Extract authors (combine names into a single string)\n    # Making this section more robust as well, similar to fieldsOfStudy\n    authors_value = paper.get('authors')\n    author_names_list = []\n    if isinstance(authors_value, list):\n        for author_entry in authors_value:\n            if isinstance(author_entry, dict):\n                author_names_list.append(author_entry.get('name', ''))\n            # Optional: if author entries could be just strings in the list\n            # elif isinstance(author_entry, str):\n            #     author_names_list.append(author_entry)\n    flat_data['authors'] = '; '.join(author_names_list)\n\n    # TLDR\n    if 'tldr' in paper and isinstance(paper['tldr'], dict):\n      flat_data['tldr_text'] = paper['tldr'].get('text','')\n    else:\n      flat_data['tldr_text'] = ''\n\n    # --- CORRECTED FieldsOfStudy ---\n    fieldsOfStudy_value = paper.get('fieldsOfStudy') # Get the actual value (could be list, None, or something else)\n    \n    if isinstance(fieldsOfStudy_value, list):\n        # Ensure all elements are strings and filter out any None elements within the list\n        string_elements = [str(item) for item in fieldsOfStudy_value if item is not None]\n        flat_data['fieldsOfStudy'] = '; '.join(string_elements)\n    elif isinstance(fieldsOfStudy_value, str): # If it's a single string, use it as is\n        flat_data['fieldsOfStudy'] = fieldsOfStudy_value\n    else: # Handles None or any other unexpected non-list, non-string types by defaulting to an empty string\n        flat_data['fieldsOfStudy'] = ''\n    # --- END CORRECTION ---\n\n    return flat_data\n\ndef write_papers_to_csv(papers, csv_file):\n    # Define fieldnames based on what flatten_paper_data produces\n    # It's good practice to derive this from a sample flattened dict or ensure consistency\n    # For now, using the manually defined list from your code.\n    fieldnames = [\n        'paperId', 'title', 'abstract', 'url', 'referenceCount', 'citationCount',\n        'publicationDate', 'DOI', 'journal_name', 'journal_pages', 'journal_volume',\n        'openAccessPdf_url', \n        'authors', 'tldr_text', 'fieldsOfStudy'\n    ]\n    # Ensure all keys produced by flatten_paper_data are in fieldnames,\n    # or handle missing keys gracefully if that's a possibility.\n\n    file_exists = os.path.isfile(csv_file)\n\n    with open(csv_file, \"a\", newline='', encoding='utf-8') as csvfile:\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames, extrasaction='ignore') # 'ignore' unknown fields\n\n        if not file_exists or os.stat(csv_file).st_size == 0:\n            writer.writeheader()\n\n        for paper_item in papers: # Renamed 'paper' to 'paper_item' to avoid conflict with module name\n            if paper_item is None: # Add a check for None paper items in the list\n                print(\"Warning: Found a None item in the papers list, skipping.\")\n                continue\n            flat_data = flatten_paper_data(paper_item)\n            writer.writerow(flat_data)\n            \nCSV_FILE = \"/kaggle/working/papers.csv\" # Define your CSV file name\nif 'detailed_result' in locals() or 'detailed_result' in globals():\n    write_papers_to_csv(detailed_result, CSV_FILE) \n    print(f\"Data written to {CSV_FILE}\")\nelse:\n    print(\"Error: 'detailed_result' is not defined. Please ensure it contains your paper data.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T11:09:07.937774Z","iopub.execute_input":"2025-05-08T11:09:07.938412Z","iopub.status.idle":"2025-05-08T11:09:07.982760Z","shell.execute_reply.started":"2025-05-08T11:09:07.938382Z","shell.execute_reply":"2025-05-08T11:09:07.982157Z"}},"outputs":[{"name":"stdout","text":"Data written to /kaggle/working/papers.csv\n","output_type":"stream"}],"execution_count":120},{"cell_type":"code","source":"df2 = pd.read_csv(CSV_FILE)\n\nmerged_df = pd.merge(df1, df2, on=['paperId'],\n    how='inner')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T11:19:50.299024Z","iopub.execute_input":"2025-05-08T11:19:50.299367Z","iopub.status.idle":"2025-05-08T11:19:50.329761Z","shell.execute_reply.started":"2025-05-08T11:19:50.299345Z","shell.execute_reply":"2025-05-08T11:19:50.329231Z"}},"outputs":[],"execution_count":127},{"cell_type":"code","source":"merged_df.to_csv(\"output.csv\", index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T11:19:51.487861Z","iopub.execute_input":"2025-05-08T11:19:51.488175Z","iopub.status.idle":"2025-05-08T11:19:51.527004Z","shell.execute_reply.started":"2025-05-08T11:19:51.488153Z","shell.execute_reply":"2025-05-08T11:19:51.526381Z"}},"outputs":[],"execution_count":128},{"cell_type":"code","source":"merged_df","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
