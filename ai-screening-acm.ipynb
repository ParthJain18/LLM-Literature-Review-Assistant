{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11746021,"sourceType":"datasetVersion","datasetId":7373664}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Input","metadata":{}},{"cell_type":"code","source":"# File path\nBIB_FILE = \"/kaggle/input/acm-thematic/acm.bib\"\n# Provide Gemini API keys within as strings the list. (For API key rotation, to avoid rate limits)\ngemini_api_keys = []\n# Provide research objectives (Used within the prompt for screening)\nresearch_objectives = \"To study the trends in automation in thematic analysis or qualitative analysis using LLMs\"\n# Provide the criteria by which the LLM should decide whether to accept the paper or not.\ndecision_criteria = \"Only accept papers where LLMs or AI tools are directly used for aiding or conducting thematic analysis or qualitative analysis\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loading data","metadata":{}},{"cell_type":"code","source":"!pip install bibtexparser -q","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import bibtexparser\nimport pandas as pd","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(BIB_FILE, encoding=\"utf-8\") as bibtex_file:\n    bib_database = bibtexparser.load(bibtex_file)\n\nentries = bib_database.entries","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df1 = pd.DataFrame(entries)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# AI Screening","metadata":{}},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\nimport os\nimport time\nimport json\nimport random\nimport csv","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def chunked(iterable, size):\n    for i in range(0, len(iterable), size):\n        yield iterable[i:i + size]\n\ndef build_prompt(papers):\n    prompt = (\n        f\"\"\"You are a research assistant helping screen academic papers for a specific research goal.\\n\n        Here are a few papers. For each paper, decide whether it aligns with the research objectives and meets the criteria. \n        Research objectives are: {research_objectives}\n        You should return your decision as true if it meets the following criteria: {decision_criteria}\n        Give a general overview ('thoughts'), a binary decision, whether to include the paper to study or not ('decision' = true/false), and an optional note.\\n\\n\n        \"\"\"\n    )\n    for idx, paper in enumerate(papers, start=1):\n        if isinstance(paper, dict):\n\n            prompt += (\n                f\"Paper {idx}:\\n\"\n                f\"Title: {paper.get('title', 'N/A')}\\n\"\n                f\"Abstract: {paper.get('abstract', 'N/A')}\\n\\n\"\n                f\"keywords: {paper.get('keywords', 'N/A')}\\n\\n\"\n            )\n    prompt += (\n        \"Respond with a JSON list of objects, each with keys: 'thoughts', 'decision', and 'note', \"\n        \"in the same order as the papers.\"\n    )\n    return prompt\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"CSV_FILE = \"/kaggle/working/screened_papers.csv\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"processed_ids = set()\nif os.path.exists(CSV_FILE):\n    with open(CSV_FILE, newline='', encoding='utf-8') as f:\n        reader = csv.DictReader(f)\n        processed_ids = {row[\"ID\"] for row in reader}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MAX_RETRIES = 5\nINITIAL_BACKOFF = 2\n\nwith open(CSV_FILE, \"a\", newline='', encoding='utf-8') as csvfile:\n    writer = csv.DictWriter(csvfile, fieldnames=[\"ID\", \"thoughts\", \"decision\", \"note\"])\n    if os.stat(CSV_FILE).st_size == 0:\n        writer.writeheader()\n\n    unprocessed = [paper for paper in entries if paper['ID'] not in processed_ids]\n\n    for i, batch in enumerate(chunked(unprocessed, 3)):\n        retries = 0\n        while retries < MAX_RETRIES:\n            try:\n                key_index = i % len(gemini_api_keys)\n                genai_client = genai.Client(api_key=gemini_api_keys[key_index])\n                model = \"gemini-2.0-flash\"\n                prompt_text = build_prompt(batch)\n                contents = [\n                    types.Content(\n                        role=\"user\",\n                        parts=[\n                            types.Part(text=prompt_text),\n                        ],\n                    ),\n                ]\n\n                generate_content_config = types.GenerateContentConfig(\n                        response_mime_type=\"application/json\",\n                        response_schema=genai.types.Schema(\n                            type = genai.types.Type.ARRAY,\n                            items = genai.types.Schema(\n                                type = genai.types.Type.OBJECT,\n                                required = [\"thoughts\", \"decision\"],\n                                properties = {\n                                    \"thoughts\": genai.types.Schema(\n                                        type = genai.types.Type.STRING,\n                                    ),\n                                    \"decision\": genai.types.Schema(\n                                        type = genai.types.Type.BOOLEAN,\n                                    ),\n                                    \"note\": genai.types.Schema(\n                                        type = genai.types.Type.STRING,\n                                    ),\n                                },\n                            ),\n                        ),\n                    )\n\n\n                result = genai_client.models.generate_content(\n                    model=model,\n                    contents=contents,\n                    config=generate_content_config\n                )\n\n                parsed_result = result.text\n                response_json = json.loads(parsed_result) if isinstance(parsed_result, str) else parsed_result\n                \n                for paper, response in zip(batch, response_json):\n                    writer.writerow({\n                        \"ID\": paper['ID'],\n                        \"thoughts\": response.get(\"thoughts\", \"\"),\n                        \"decision\": response.get(\"decision\", \"\"),\n                        \"note\": response.get(\"note\", \"\"),\n                    })\n                    csvfile.flush()\n\n                print(f\"Batch {i + 1} processed and saved.\")\n                break  # exit retry loop\n\n            except Exception as e:\n                print(f\"Error in batch {i + 1}, retrying ({retries + 1}/{MAX_RETRIES})...\")\n                print(f\"Exception: {e}\")\n                time.sleep(INITIAL_BACKOFF * (2 ** retries) + random.uniform(0, 1))\n                retries += 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Merging Data","metadata":{}},{"cell_type":"code","source":"df2 = pd.read_csv(CSV_FILE)\n\ndf2.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merged_df = pd.merge(df1, df2, on=['ID'], how='inner')\nmerged_df.to_csv(\"output.csv\", index = False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merged_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}